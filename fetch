#!/usr/bin/env python3

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import os
import os.path
import hashlib

index = open('index.md', 'w')
checksums = {
    alg: open(f'{alg.upper()}SUM', 'w')
    for alg
    in ['md5', 'sha1', 'sha256', 'sha512']
}

index_url = 'https://www.virtualhere.com/usb_server_software'

session = requests.Session()

print('Downloading', index_url)
response = session.get(index_url)
response.raise_for_status()

soup = BeautifulSoup(response.content, 'lxml')
for item in soup.find_all('li'):

    link = item.find('a')
    if not link:
        continue
    description = link.get_text()

    is_optimised = 'Optimized for' in description

    binary_url = link.get('href', None)
    if binary_url and binary_url.startswith('/sites/default/files/usbserver/'):

        binary_url = urljoin(index_url, binary_url)
        filename = os.path.basename(binary_url)

        print('Downloading', binary_url, description)
        response = session.get(binary_url)
        response.raise_for_status()

        if is_optimised:
            local_filename = os.path.join('optimised', filename)
        else:
            local_filename = os.path.join('generic', filename)

        try:
            os.mkdir(os.path.dirname(local_filename))
        except FileExistsError:
            pass

        with open(local_filename, 'wb') as f:
           f.write(response.content)

        index.write(f'- [{description}]({local_filename}\n')
        for alg, f in checksums.items():
            checksum = hashlib.new(alg, response.content).hexdigest()
            f.write(f'{checksum} *{local_filename}\n')

index.close()
for f in checksums.values():
    f.close()
